## Working with files in a Data Lake
- core resource in SAWS is a DL
- DL: place in which data can be stored and processed at scale
- a WS has a default data lake
	- implemented as a linked service to an Azure Data Lake storage Gen2 Container
- we can add linked services for multiple data lakes that are based on different storage p/f as required

## Ingesting and transforming data with PP
- in most enterprise DA solns, data is extracted from multiple operational sources and transferred to a central DL or DWH for analysis
- ASA includes built in support for creating, running, and managing pipelines
- these pipelines orchestrate the activities necessary to retrieve data from a range of sources, transform and load the result to a analytical store
- pipelines in ASA are based on the same underlying tech as AData Factory
	- if already familiar with ADF, we can leverage our existing skill to build pipelines

## Querying and manipulating data with SQL
- ASA supports SQL-based data querying and manipulation
- through 2 kinds of SQL pool that are based on the SQL server relational DB engine
	- built-in serverless pool that is optimized for using relational SQL semantics to query file-based data in a data lake
		- ServerlessSQLP: query service over the data in our data lake
	- custom dedicated SQL pools that host relational DWHs
	- what are pools here?
- ASSQL system uses a distributed query processing model
	- since parallelism possible, it is highly scalable solution for relational data processing
- we can use the built-in serverless pool for **cost-effective** analysis of file data in the data lake
- use dedicated SQL pools to create relational dwhs for enterprise data modeling and reporting

## Processing and analyzing data with Apache Spark
- in ASA, we can create one or more Spark pools and use interactive notebooks to combine code and notes
	- Spark Pool is a set of md
	- defines compute resource requirements and associated behavior char when a Spark instance is instantiated

## Exploring data with Data Explorer
- ASDE is a data processing engine in ASA
	- based on the Azure-Data-Explorer service
- DE uses an intuitive query syntax named Kusto query language(KQL)
	- enables high performance, low-latency analysis of batch and streaming data