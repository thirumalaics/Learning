## CAP Theory
- defines requirements in a distributed systems with replication
- Consistency
	- there are certain dbs that allow for very high data consistency
	- allow for txns
		- withdrawing money and depositing in another account
		- if one happens and the other does not, the data will be inconsistent with the real life scenario
	- certain classes of dbs supports strong consistency
	- all clients see the same data at the same time(among replicated copies)
- availability
	- uptime
	- data availability
	- we have the ability to make copies of data so that if one copy goes down, we have others
		- for some or all of the users
- partitioning
	- split data across multiple processing locations or machines
	- scalable
- it is said that dbs can only meet two of the CAP components
	- this is where HD comes in, it does not address CA aspects well
	- HD built for scalability
- HD run on v-v-cheap servers
	- designed for partitioning
	- makes 3 copies of the data by default
	- if any of these 3 copies become bad because the h/w is corrupted, we pull-out old and put-in new h/w
		- HDFS will automatically take care of the copy process
	- flexibility one char of HD


## Understanding BD
- 2 kinds of data
	- line of business data
		- usually txnal
		- not a good fit for Hadoop
		- consistency is a must
	- behavioral data
		- data that would be processed as a group rather than individually queried
		- large in size
		- not critical enough to be highly consistent
		- good for Hadoop
- hadoop data might get into RDB or NOSQLDB and then queried there 
	- hd very often comes with the need to supplement with NoSQL sys