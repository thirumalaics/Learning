## HDFS
- two modes for implementation
	- distributed or pseudo-distributed
		- distributed:3 copies, pd: uses the HDFS, but designed for testing, usually implemented on a single node on a single machine
- we can run hadoop with the regular FS
	- called the standalone mode
- cloud file system can be used
	- when we are deploying hadoop in cloud
- another consideration to be made is how the FS that we choose and JVM interacts
	- if we deploy in single node, then we can use local FS and single JVM for all HD processes
	- if deployed in pseudo-distributed mode, use HDFS and java daemons are going to run all processes on a single machine
	- if we run in fully distributed mode, we are going to use HDFS with triple replication and daemons are going to run in various locations depending on where we choose to place them
		- this placement choice is important for prod wls
- all are daemons in the below diagram
- 3 diff servers below
- name and data node are daemons as well
![[Pasted image 20230706181732.png]]

## Hadoop Cluster Components
![[Pasted image 20230706181947.png]]
- MR V2 is the distributed app that runs on  top of YARN
- Hive is a SQL-like query language that is used to query against HBase
- Pig for ETL-like processes
- oozie is also for scheduling
- Sqoop is for data exchange b/w other systems
	- typically for relations sys
![[Pasted image 20230706182837.png]]
- HUE is a UI FW to make interaction with HD easy

## Apache Spark
- in-mem distributed data processing
- commercial distros at Databricks
- compatible with HD data, clusters and YARN
- process data in HDFS,HBase,Hive and in any hadoop ecosys i/p format