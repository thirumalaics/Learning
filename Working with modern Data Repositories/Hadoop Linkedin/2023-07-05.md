## What is Hadoop
- two components
	- open source data storage or HDFS
	- processing API, called as MapReduce
 - often deployed with other projects as well
- important to understand what are hadoop distributions
	- the first set of distributions are 100% open source
	- core distribution is called Apache Hadoop
		- many diff versions
		- might not be stable for professional wls
	- commercial distributions more stable
		- comes as a wrap around of some open source version
		- additional tooling, monitoring provided
		- most pop: cloudera
- clouds have their own version of HD
	- AWS has Commercial-distro MapR on it
	- not all CVs are available on all clouds
- HDFS designed for BD
	- size of each file is larger
	- often called chunks
	- diff from our normal FS
	- important to plan on how to layout our files
- MR written in Java
	- very technical
	- low level programming
- requirement to provide a higher level of abstraction was raised
	- for this there is HBase
	- makes the hadoop data accessible to less technical teams
- there is no requirement for values in data column of HBASE tables
	- because there is no restriction on columns: wide-column-store
	- schema on read
		- we will need to impose some schema in order to query or get the info out
		- not needed when we write 
- we will be writing a create table statement which will then perform an abstraction against HDFS so that we can then work with the data as if it is a quasi tabular format
	- hive is used to query this data
![[Pasted image 20230705175826.png]]

## JVM
- Hadoop processes or execution activities run in separate JVMs
- JVM : process
	- for executing byte code of a executable program
- does not share state
	- db processing systems, state is shared
- JVM implementations for Haddoop v1.0 diff from 2.0+