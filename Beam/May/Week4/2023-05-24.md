## File-based I/p and O/p data
## Reading from multiple locations
- we can using file globbing while providing a path
	- all files that match the glob are read
	- glob operators are filesystem-specific
![[Pasted image 20230524160707.png]]
- all i/p files with prefix "input-" and the suffix ".csv" are read
- another way to read from different sources into a single PColl
	1. read each one independently
	2. use flatten

## Writing to multiple o/p files
- by default, write transforms write to multiple o/p files
	- when we produce a file name to a write transform, it is used as a prefix for all op files that the transform produces
	- we can also specify a suffix
![[Pasted image 20230524180903.png]]
- each file has tag number b/w the prefix and suffix

## Schemas
- common beam sources produces JSON, Avro, Protocol Buffer or db row-objects
	- schema can be defined by examining the type
- even within a SDK, simple JAVA POJOs(or equivalent structures in other languages) are often used as intermediate types
	- these structures that can be inferred by inspecting the class
- by understanding the structure of a pipeline's records, we can provide much more concise APIs for data processing

## What is a schema
- most structured records share some common chars:
	1. they can be subdivided into separate named fields
		- usually have string names
		- sometimes numerical indices
	2. there is a confined list of primitive types that a field can have
		- often match primitive types in most prog langs
	3. often a field type can be marked as optional or required
- schemas provide an abstract description of types involved
	- abstracted away from any specific prog lang
- PColl with a schema does not need to have a coder specified
	- beam knows how to encode and decode Schema rows