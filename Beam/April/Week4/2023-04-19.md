- beam's vision:
	- Choose our language, write data processing pipeline, run this pipeline using a runner of our choice, and do all of this for both batch and realtime data at the same time
- the price we pay for this flexibility:
	- bigger overhead in terms of CPU and/or memory usage
	- beam community works to minimize these overheads

## building pipeline
1. we need to build a pipeline object
	- this is a container for the DAG that represents the data transformations needed to produce o/p
```
import apache_beam as beam

with beam.Pipeline() as pipeline:
  pass  # build your pipeline here
```
2. Fill the pipeline with data
	- in beam, data is represented by a PCollection object
	- Pcollection object(parallel collection) can be imagined as a line (an edge) connecting two vertices(PTransforms, or parallel transforms) in the pipeline's DAG
	- we create a Pcollection by reading the data from an external source using [[Beam's Source API]](contains adapters that help reading)
		- or we can create a Pcollection of data stored in an in-memory collection(ex: string) class in our driver program
		- or from other Pcollections
		- all adapters return a Pcollection, whose elements represent the data records in that source
	- each Ptransform can have one main o/p and possibly multiple side o/p Pcollections
	- each Pcollection must be consumed by another Ptransform or the Pcollection might be excluded from the execution
```
import apache_beam as beam

with beam.Pipeline() as pipeline:
  lines = (
      pipeline
      | beam.Create([
          'To be, or not to be: that is the question: ',
          "Whether 'tis nobler in the mind to suffer ",
          'The slings and arrows of outrageous fortune, ',
          'Or to take arms against a sea of troubles, ',
      ]))  
```
- we connect PTransform to a Pcollection by applying the PTransform on the PCollection:
	   `PCollection<String> words = input.apply(Tokenize.of());`
		![[Pasted image 20230419174936.png]]
	- tokenize takes i/p lines and splits each line into words
	- one thing I noted is that Pcollection has a apply method, to this apply method the Ptransform is passed as an argument
		- apply method returns a Pcollection as a result
1. After the pipeline structure is defined, we have to run the pipeline
		`pipeline.run().waitUntilFinish();`
	- this line causes the pipeline to be passed to a runner(configured in the pipeline; if omitted, it defaults to the runner available in the Classpath)
	- standard default runner is the DirectRunner, which executes the pipeline in the local JVM only
	- this runner is only suitable for testing