## Core Transforms
- these core transforms represents different processing patterns
	- ParDo
	- GroupByKey
	- CoGroupByKey
	- Combine
	- Flatten
	- Partition

## ParDo
- for generic parallel processing
- processing pattern is similar to the MAP phase of MapReduce
- ParDo transform considers each element in the Pcoll
	- performs some processing fn on the element
	- emits zero, one, or multiple elements to an o/p PColl
- Common Use cases for ParDo:
	- filtering a dataset
		- as the fn is applied to every element in the PColl, we can code to emit each element based only based on some condition
	- formating or type conversion each element
		- when the elements are of diff type or format than we want
		- output the result to a new PColl
	- extracting parts of each element in a data set
	- performing computations on each element in a data set
- when we apply a ParDo transform, we will need to provide user code in the form of a DoFn obj
	- hence we need to subclass DoFn
- DoFn is a Beam SDK class that defines a distributed processing fn
- when we create a subclass of DoFn,our subclass should adhere to requirements for writing user code for beam transforms

## Applying ParDo
- like all transforms, apply ParDo by calling the apply method on the input Pcollection
	- pass ParDo as an argument

```
words = pipeline | beam.Create(["str1","str2","str2"])

class WordLen(beam.DoFn):
	def process(self, element):
		return [len(element)]

words_length = words | beam.ParDo(WordLen())
```

## Creating a DoFn
- inside the DoFn subclass, we will write a method process where we provide the actual processing logic
- beam handles extracting each element from the input PCollection
- our process method should accept a argument called `element`
	- i/p element
- we should return an iterable with the o/p value(s)
- we can emit individual elements with `yield` statments
	- use `yield from` to emit all elements from an iterable
	- i think we have to use  yield when we want to return multiple elements for the same i/p element
- our process method should not have both yield and return statments in the same process
	- leads to incorrect behavior
- a DoFn generally gets invoked one or more times to process some arbitrary **bundle** of elements
- beam does not guarantee exact num of invocations
- might be called multiple times on a given worker to account failures
- we can cache info across multiple calls
	- must make sure that info store does not depend on the number of invocations
- our method should meet these req:
	- element arg or any side i/ps provided should not be modified
	- once we output a value using yield or return, we should not modify that value in any way